# **Boris Hanin**

![image](https://user-images.githubusercontent.com/17192187/208241293-8cc211ec-8af6-446d-b4aa-e10e4b7581af.jpeg)
 
## **About Me**
I am an Assistant Professor at [Princeton ORFE](https://orfe.princeton.edu/) since 2019. I work on **deep learning, probability, and spectral asymptotics.** Prior to Princeton, I was an Assistant Professor in Mathematics at Texas A&M, an NSF Postdoc at MIT Math, and a PhD student in Math at Northwestern, where I was supervised by Steve Zelditch. 

**Funding**: I am grateful to be supported by an NSF CAREER grant DMS-2143754 and NSF grants DMS-1855684, DMS-2133806. I am also a consultant for an ONR MURI on Foundations of Deep Learning. See my [CV](/CV.pdf) for more information.

**Email**: bhanin 'at' princeton.edu



## **News**
- I am currently looking for grad students and postdocs. If you are a student at Princeton looking to work on deep learning theory, feel free to reach out (see also this somewhat tongue-in-cheek [writeup](/Working_With_Me.pdf)).
-  I am organizing the [2023 Princeton Deep Learning Theory Summer School](https://mlschool.princeton.edu/). 

## **Students**
I am fortunate to supervise [Pierfrancesco Beneventano](https://pierbeneventano.github.io/), [Samy Jelassi](https://sjelassi.github.io/), and [Kaiqi Jiang](https://ece.princeton.edu/people/kaiqi-jiang).

## **Papers** [ArXiv](https://arxiv.org/a/hanin_b_1.html)

### **Deep Learning and Random Matrix Theory**
1. Maximal Initial Learning Rates in Deep ReLU Networks, with G. Iyer and D. Rolnick [ArXiv](https://arxiv.org/abs/2212.07295)
1. Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis with W. Chen, W. Huang, X. Gong, Z. Wang, NeurIPS 2022 [ArXiv](https://arxiv.org/abs/2205.05662)
3. Correlation Functions in Random Fully Connected Neural Networks at Finite Width (2022)  [ArXiv](https://arxiv.org/abs/2204.01058)
4. Ridgeless Interpolation with Shallow ReLU Networks in 1D is Nearest Neighbor Curvature Extrapolation and Provably Generalizes on Lipschitz Functions (2021)  [ArXiv](https://arxiv.org/abs/2109.12960)
5. Random Neural Networks in the Infinite Width Limit as Gaussian Processes (2021) [ArXiv](https://arxiv.org/abs/2107.01562)
6. Non-asymptotic Results for Singular Values of Gaussian Matrix Products, with G. Paouris. GAFA (2021) [ArXiv](https://arxiv.org/abs/2005.08899)
7. Deep ReLU Networks Preserve Expected Length, with R. Jeong and D. Rolnick, ICLR 2022 [ArXiv](https://arxiv.org/abs/2102.10492)
8. Neural Network Approximation, with R. DeVore and G. Petrova, Acta Numerica (2020) [ArXiv](https://arxiv.org/abs/2012.14501)
9. How Data Augmentation affects Optimization for Linear Regression, with Y. Sun NeurIPS 2021 [ArXiv](https://arxiv.org/abs/2010.11171)
10. Products of Many Large Random Matrices and Gradients in Deep Neural Networks, with M. Nica. Communications in Mathematical Physics (2020) [ArXiv](https://arxiv.org/abs/1812.05994)
11.	Finite Depth and Width Corrections to the Neural Tangent Kernel, with M. Nica, Splotlight at ICLR 2020 [ArXiv](https://arxiv.org/abs/1909.05989)
12.	Deep ReLU Networks Have Surprisingly Few Activation Patterns, with D. Rolnick, NeurIPS 2019 [ArXiv](https://arxiv.org/abs/1906.00904)
13.	Nonlinear Approximation and (Deep) ReLU Networks, with I. Daubechies, R. DeVore, S. Foucart, and G. Petrova. Constructive Approximation (Special Issue on Deep Networks in Approximation Theory) (2019) [ArXiv](https://arxiv.org/abs/1905.02199)
15.	Complexity of Linear Regions in Deep Networks, with D. Rolnick, ICML 2019 [ArXiv](https://arxiv.org/abs/1901.09021)
17.	How to Start Training: The Effect of Initialization and Architecture, with D. Rolnick. NIPS 2018 [ArXiv](https://arxiv.org/abs/1803.01719)
18.	Which Neural Net Architectures Give Rise to Vanishing and Exploding Gradients? NIPS 2018 [ArXiv](https://arxiv.org/abs/1801.03744)
19.	Approximating Continuous Functions by ReLU Nets of Minimal Width, with M. Sellke (2017) [ArXiv](https://arxiv.org/abs/1710.11278)
20.	Universal Function Approximation by Deep Neural Nets with Bounded Width and ReLU Activations. Mathematics 2019, 7(10), 992 (Special Issue on Computational Mathematics, Algorithms, and Data Processing) [ArXiv](https://arxiv.org/abs/1708.02691)


### **Spectral Theory**

1. Scaling Asymptotics of Spectral Wigner Functions, with S. Zelditch. Journal of Physics A (Special Edition on Claritons and the Asymptotics of Ideas: the Physics of Michael Berry) (2022) [ArXiv](https://arxiv.org/abs/2207.13571)
13. Interface Asymptotics of Wigner-Weyl Distributions for the Harmonic Oscillator, with S. Zelditch. Journal d'Analyse (2022) [ArXiv](https://arxiv.org/abs/1903.12524)
15.	Interface Asymptotics of Eigenspace Wigner distributions for the Harmonic Oscillator, with S. Zelditch. Communications in PDE (2020) [ArXiv](https://arxiv.org/abs/1901.06438)
22.	Level Spacings and Nodal Sets at Infinity for Radial Perturbations of the Harmonic Oscillator, with T. Beck. International Math Research Notices, 2021. [ArXiv](https://arxiv.org/abs/1708.06434)
23.	Local Universality for Zeros and Critical Points of Monochromatic Random Waves, with Y. Canzani. Communication in Mathematical Physics, 2020. [ArXiv](https://arxiv.org/abs/1610.09438)
24.	Nodal Sets of Functions with Finite Vanishing Order, with T. Beck and S. Becker-Khan. Calculus of Variations and PDE (2018) [ArXiv](https://arxiv.org/abs/1708.06434)
25.	Scaling of Harmonic Oscillator Eigenfunctions and Their Nodal Sets Around the Caustic, with S. Zelditch and P. Zhou. Communications in Mathematical Physics. Vol. 350, no. 3, pp. 1147--1183, 2017. [ArXiv](https://arxiv.org/abs/1708.06434)
26. C^âˆž Scaling Asymptotics for the Spectral Function of the Laplacian, with Y. Canzani. The Journal of Geometric Analysis (2018) [ArXiv](http://arxiv.org/abs/1602.00730)
28. Scaling Limit for the Kernel of the Spectral Projector and Remainder Estimates in the Pointwise Weyl Law, with Y. Canzani. Analysis and PDE, Vol. 8 (2015), No. 7, pp. 1707-1731. [ArXiv](http://arxiv.org/abs/1411.0658)
29. High Frequency Eigenfunction Immersions and Supremum Norms of Random Waves, with Y. Canzani. Electronic Research Announcements. MS 22, no. 0, January 2015, pp. 76 - 86. [ArXiv](http://arxiv.org/abs/1406.2309)
31. Nodal Sets of Random Eigenfunctions for the Isotropic Harmonic Oscillator, with S. Zelditch and P. Zhou. International Mathematics Research Notices, Vol. 2015, No. 13, pp. 4813 - 4839. [ArXiv](http://arxiv.org/abs/1310.4532)


### **Zeros and Critical Points of Random Polynomials**

1. The Lemniscate Tree of a Random Polynomial, with M. Epstein and E. Lundberg. Annales Institute Henri Poincare (B), 2018. [ArXiv](https://arxiv.org/abs/1806.00521)
27.	Pairing of Zeros and Critical Points for Random Polynomials. Annales de l'Institut Henri Poincare (B) Probabilites et Statistiques. Volume 53, Number 3 (2017), 1498-1511. [ArXiv](https://arxiv.org/abs/1601.06417)
30. Pairing of Zeros and Critical Points for Random Meromorphic Functions on Riemann Surfaces</b>. Mathematics Research Letters, Vol. 22 (2015), No. 1, pp. 111-140. [ArXiv](http://arxiv.org/abs/1305.6105)
32. Correlations and Pairing Between Zeros and Critical Points of Gaussian Random Polynomials. International Math Research Notices (2015), Vol. (2), pp. 381-421. [ArXiv](http://arxiv.org/abs/1207.4734)

### **Other**
1. Contributed research to Principles of Deep Learning Theory, written by D. Roberts and S. Yaida, Cambridge University Press (2021) [ArXiv](https://arxiv.org/abs/2106.10165)
34. An Intriguing Property of the Center of Mass for Points on Quadradtic Curves and Surfaces, with L. Hanin and R. Fisher. Mathematics Maganize, v. 80, No. 5, pp. 353-362, 2007.
